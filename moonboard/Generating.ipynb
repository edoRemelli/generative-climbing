{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import defaultdict\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from load_moonboard import load_moonboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing all arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--seed\", type=int, default=0)\n",
    "parser.add_argument(\"--epochs\", type=int, default=20)\n",
    "parser.add_argument(\"--lambd\", type=int, default=0.5)\n",
    "parser.add_argument(\"--batch_size\", type=int, default=64)\n",
    "parser.add_argument(\"--learning_rate\", type=float, default=0.001)\n",
    "parser.add_argument(\"--encoder_layer_sizes\", type=list, default=[784, 256])\n",
    "parser.add_argument(\"--decoder_layer_sizes\", type=list, default=[256, 784])\n",
    "parser.add_argument(\"--latent_size\", type=int, default=30)\n",
    "parser.add_argument(\"--print_every\", type=int, default=10)\n",
    "parser.add_argument(\"--fig_root\", type=str, default='figs')\n",
    "parser.add_argument(\"--representation\", type=str, default=None)\n",
    "parser.add_argument(\"--loss\", type=str, default=\"MSE\")\n",
    "parser.add_argument(\"--test_loss\", type=str, default=\"MSE\")\n",
    "parser.add_argument(\"--net\", type=str, default=\"ResNet\")\n",
    "parser.add_argument(\"--conditional\", action='store_true')\n",
    "parser.add_argument(\"--variational\", action='store_true')\n",
    "\n",
    "\n",
    "\n",
    "args = parser.parse_args([])\n",
    "args.conditional = True\n",
    "args.lambd = 0.9\n",
    "args.epochs = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up model and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.net == \"ResNet\":\n",
    "    from models_resnet import VAE\n",
    "elif args.net == \"conv\":\n",
    "    from models_conv import VAE\n",
    "else:\n",
    "    from models import VAE\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "ts = time.time()\n",
    "\n",
    "\n",
    "\"\"\"Load the dataset\"\"\"\n",
    "class MoonBoardDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train = True):\n",
    "        self.train = train\n",
    "\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = load_moonboard()\n",
    "        self.x_train = self.x_train.transpose(0,1,3,2 ).astype(float)\n",
    "        self.x_test = self.x_test.transpose(0,1,3,2 ).astype(float)\n",
    "        self.y_train = self.y_train.reshape(-1,1).astype(int)\n",
    "        self.y_test = self.y_test.reshape(-1,1).astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.x_train)\n",
    "        else:\n",
    "            return len(self.x_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            return self.x_train[idx], self.y_train[idx]\n",
    "        else:\n",
    "            return self.x_test[idx], self.y_test[idx]\n",
    "\n",
    "dataset = MoonBoardDataset(train = True)\n",
    "dataset_test = MoonBoardDataset(train = False)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset,\n",
    "batch_size=128, shuffle=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(MoonBoardDataset(train = False),\n",
    "batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Define the loss\"\"\"\n",
    "def loss_fn(recon_x, x, mean, log_var):\n",
    "    \"\"\"\n",
    "        recon_x : reconstructed x after being through VAE or CVAE\n",
    "        x : original x\n",
    "        mean : center of the gaussian in average\n",
    "        log_var : related to the standard deviation \n",
    "    \"\"\"\n",
    "    if args.loss == \"BCE\":\n",
    "        recon_loss = torch.nn.BCELoss()(\n",
    "        recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "    elif args.loss == \"MSE\":\n",
    "        recon_loss = torch.nn.MSELoss()(recon_x.view(-1,3*18*11), x.view(-1, 3*18*11))\n",
    "    elif args.loss == \"L1\":\n",
    "        recon_loss = torch.nn.L1Loss()(recon_x.view(-1,3*18*11), x.view(-1, 3*18*11))\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())/x.size(0)\n",
    "\n",
    "    return (args.lambd * recon_loss + (1 - args.lambd) * KLD) \n",
    "\n",
    "def test_loss_fn(recon_x, x, mean, log_var):\n",
    "    if args.loss == \"BCE\":\n",
    "        recon_loss = torch.nn.BCELoss()(\n",
    "        recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "    elif args.loss == \"MSE\":\n",
    "        recon_loss = torch.nn.MSELoss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "    elif args.loss == \"L1\":\n",
    "        recon_loss = torch.nn.L1Loss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "    KLD = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())/x.size(0)\n",
    "\n",
    "    return (args.lambd * recon_loss + (1 - args.lambd) * KLD)  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1163896\n"
     ]
    }
   ],
   "source": [
    "vae = VAE(\n",
    "    encoder_layer_sizes=args.encoder_layer_sizes,\n",
    "    latent_size=args.latent_size,\n",
    "    decoder_layer_sizes=args.decoder_layer_sizes,\n",
    "    conditional=args.conditional, variational = args.variational,\n",
    "    num_labels=13 if args.conditional else 0).to(device)\n",
    "\n",
    "\"\"\"Define the optimizer\"\"\"\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=args.learning_rate)\n",
    "\n",
    "\n",
    "\"\"\"Prints the number of parameters in the model\"\"\"\n",
    "print(sum(p.numel() for p in vae.parameters()))\n",
    "\n",
    "logs = defaultdict(list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.8 |Anaconda, Inc.| (default, Feb 11 2019, 15:03:47) [MSC v.1915 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=13):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "inception_model = torch.load(\"inception_model.trch\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inception score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_score(imgs, inception_model, splits = 1):\n",
    "\n",
    "    N = len(imgs)    \n",
    "    split_scores = []\n",
    "    \n",
    "    preds = nn.Softmax(dim = 1)(inception_model(imgs))\n",
    "    \n",
    "\n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = torch.mean(part, 0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx.cpu().detach().numpy(), py.cpu().detach().numpy()))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/70 Batch 0000/32, Loss 0.023888 KL 0.051113 Recon loss 0.020863\n",
      "Epoch 01/70 Batch 0010/32, Loss 0.018473 KL 0.032722 Recon loss 0.016890\n",
      "Epoch 01/70 Batch 0020/32, Loss 0.016298 KL 0.023750 Recon loss 0.015470\n",
      "Epoch 01/70 Batch 0030/32, Loss 0.015209 KL 0.019516 Recon loss 0.014730\n",
      "Epoch 01/70 Batch 0032/32, Loss 0.015397 KL 0.020832 Recon loss 0.014793\n",
      "\n",
      "Test loss :  0.01522843289889561\n",
      "Inception score  (1.1047145, 0.0)\n",
      "Epoch 02/70 Batch 0000/32, Loss 0.015432 KL 0.021637 Recon loss 0.014742\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-7f0173c67cf1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracker_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mtracker_epoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mtracker_epoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(args.epochs):\n",
    "\n",
    "    tracker_epoch = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "    \"\"\"Do training\"\"\"\n",
    "\n",
    "    for iteration, (x, y) in enumerate(data_loader):\n",
    "        \"\"\"Send data to GPU\"\"\"\n",
    "        x, y = x.type(torch.FloatTensor).to(device), y.type(torch.FloatTensor).to(device)\n",
    "        \n",
    "\n",
    "        \"\"\"CVAE or VAE generates data\"\"\"\n",
    "        if args.conditional:\n",
    "            recon_x, mean, log_var, z = vae(x, y)\n",
    "        elif args.variational:\n",
    "            recon_x, mean, log_var, z = vae(x)\n",
    "        else:\n",
    "            recon_x, z = vae(x)\n",
    "\n",
    "        for i, yi in enumerate(y):\n",
    "            id = len(tracker_epoch)\n",
    "            for j in range(args.latent_size):\n",
    "                tracker_epoch[id][str(j)] = z[i, j].item()\n",
    "            tracker_epoch[id]['label'] = yi.item()\n",
    "\n",
    "\n",
    "        \"\"\"Compute loss\"\"\"\n",
    "        if args.variational or args.conditional:                \n",
    "            loss = loss_fn(recon_x, x, mean, log_var)\n",
    "            \"\"\"Compute KL divergence and binary crossentropy\"\"\"\n",
    "            diverge = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp()) / x.size(0)\n",
    "            if args.loss == \"MSE\":\n",
    "                recon_loss = torch.nn.MSELoss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "            elif args.loss == \"BCE\":\n",
    "                recon_loss = torch.nn.functional.binary_cross_entropy(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11)) \n",
    "            elif args.loss == \"L1\":\n",
    "                recon_loss = torch.nn.L1Loss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "            logs['KL divergence'].append(-diverge.item())\n",
    "            logs['Reconstruction Loss'].append(recon_loss.item())\n",
    "\n",
    "        else:\n",
    "            if args.loss == \"MSE\":\n",
    "                loss = torch.nn.MSELoss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "            elif args.loss == \"BCE\":\n",
    "                loss = torch.nn.functional.binary_cross_entropy(recon_x.view(-1, 3,18,11), x.view(-1, 3,18,11)) \n",
    "            elif args.loss == \"L1\":\n",
    "                loss = torch.nn.L1Loss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "            #elif args.loss == \"Hinge\":\n",
    "            #    loss = torch.nn.MarginRankingLoss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        logs['loss'].append(loss.item()/x.size(0))\n",
    "\n",
    "\n",
    "        if iteration % args.print_every == 0 or iteration == len(data_loader)-1:\n",
    "            if args.variational or args.conditional:\n",
    "                #print(\" \"*50, end = \"\\r\")\n",
    "                print(\"Epoch {:02d}/{:02d} Batch {:04d}/{:d}, Loss {:f} KL {:f} Recon loss {:f}\".format(\n",
    "                    epoch+1, args.epochs, iteration, len(data_loader)-1, loss.item(), diverge.item(), recon_loss.item()))#, end=\"\\r\")\n",
    "\n",
    "            else:\n",
    "                #print(\" \"*50, end=\"\\r\")\n",
    "                print(\"Epoch {:02d}/{:02d} Batch {:04d}/{:d}, Loss {:f} \".format(\n",
    "                    epoch+1, args.epochs, iteration, len(data_loader)-1, loss.item()))#, end=\"\\r\")\n",
    "\n",
    "\n",
    "            \"\"\"Create images from only latent variable\"\"\"\n",
    "            if args.conditional:\n",
    "                c = torch.arange(0, 10).long().unsqueeze(1)\n",
    "                x = vae.inference(n=c.size(0), c=c)\n",
    "            else:\n",
    "                x = vae.inference(n=10)\n",
    "\n",
    "\n",
    "            plt.figure()\n",
    "            plt.figure(figsize=(5, 10))\n",
    "            for p in range(10):\n",
    "                plt.subplot(5, 2, p+1)\n",
    "                if args.conditional:\n",
    "                    plt.text(\n",
    "                        0, 0, \"c={:d}\".format(c[p].item()), color='black',\n",
    "                        backgroundcolor='white', fontsize=8)\n",
    "                plt.imshow(x[p].view( 3,18, 11).data.cpu().numpy().transpose(1,2,0))\n",
    "                plt.axis('off')\n",
    "\n",
    "            if not os.path.exists(os.path.join(args.fig_root, str(ts))):\n",
    "                if not(os.path.exists(os.path.join(args.fig_root))):\n",
    "                    os.mkdir(os.path.join(args.fig_root))\n",
    "                os.mkdir(os.path.join(args.fig_root, str(ts)))\n",
    "\n",
    "            plt.savefig(\n",
    "                os.path.join(args.fig_root, str(ts),\n",
    "                             \"E{:d}I{:d}.png\".format(epoch, iteration)),\n",
    "                dpi=300)\n",
    "            plt.clf()\n",
    "            plt.close('all')\n",
    "\n",
    "            \"\"\"Reconstruction of already existing images\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "            rnd_id = random.sample(range(1, len(dataset_test)), 5)\n",
    "            x = [torch.from_numpy(np.array(dataset_test[i][0])).type(torch.FloatTensor) for i in rnd_id]\n",
    "            x = torch.stack(x)\n",
    "            x = x.to(device)\n",
    "\n",
    "            c = [torch.from_numpy(np.array(dataset_test[i][1])).type(torch.FloatTensor) for i in rnd_id]\n",
    "            c = torch.stack(c).view(5,1)\n",
    "            c = c.to(device)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            if not args.conditional:\n",
    "                x = torch.cat((x,vae(x, testing = True)[0].view(5,3,18, 11)),0)\n",
    "            else:\n",
    "                x = torch.cat((x,vae(x,c, testing = True)[0].view(5,3,18, 11)),0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plt.figure()\n",
    "            plt.figure(figsize=(5, 10))\n",
    "            for p in range(5):\n",
    "                plt.subplot(5, 2, 2*p+1)\n",
    "                if args.conditional:\n",
    "                    plt.text(\n",
    "                        0, 0, \"c={:f}\".format(c[p].item()), color='black',\n",
    "                        backgroundcolor='white', fontsize=8)\n",
    "                plt.imshow(x[p].view(3,18,11).data.cpu().numpy().transpose(1,2,0))\n",
    "                plt.axis('off')\n",
    "\n",
    "                plt.subplot(5, 2, 2*p+2)\n",
    "                if args.conditional:\n",
    "                    plt.text(\n",
    "                        0, 0, \"c={:f}\".format(c[p].item()), color='black',\n",
    "                        backgroundcolor='white', fontsize=8)\n",
    "                plt.imshow(x[p+5].view(3,18,11).data.cpu().numpy().transpose(1,2,0))\n",
    "                plt.axis('off')\n",
    "\n",
    "            if not os.path.exists(os.path.join(args.fig_root, str(ts))):\n",
    "                if not(os.path.exists(os.path.join(args.fig_root))):\n",
    "                    os.mkdir(os.path.join(args.fig_root))\n",
    "                os.mkdir(os.path.join(args.fig_root, str(ts)))\n",
    "\n",
    "            plt.savefig(\n",
    "                os.path.join(args.fig_root, str(ts),\n",
    "                             \"Reconstruction E{:d}I{:d}.png\".format(epoch, iteration)),\n",
    "                dpi=300)\n",
    "            plt.clf()\n",
    "            plt.close('all')\n",
    "    print(\"\")\n",
    "\n",
    "    \"\"\"Test model\"\"\"\n",
    "\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        bs = 0\n",
    "        for iteration, (x, y) in enumerate(data_loader_test):\n",
    "            #Send data to GPU\n",
    "            x, y = x.type(torch.FloatTensor).to(device), y.type(torch.FloatTensor).to(device)\n",
    "\n",
    "            #CVAE or VAE generates data\n",
    "            if args.conditional:\n",
    "                recon_x, mean, log_var, z = vae(x, y, testing = True)\n",
    "            elif args.variational:\n",
    "                recon_x, mean, log_var, z = vae(x, testing = True)\n",
    "            else:\n",
    "                recon_x, z = vae(x, testing = True)\n",
    "\n",
    "            if not args.conditional and not args.variational:\n",
    "\n",
    "                if args.test_loss == \"MSE\":\n",
    "                    loss_res = torch.nn.MSELoss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11))\n",
    "                elif args.test_loss == \"BCE\":\n",
    "                    loss_res = torch.nn.functional.binary_cross_entropy(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11)) \n",
    "                elif args.test_loss == \"L1\":\n",
    "                    loss_res = torch.nn.L1Loss()(recon_x.view(-1, 3*18*11), x.view(-1, 3*18*11)) \n",
    "            else:\n",
    "                loss_res = test_loss_fn(recon_x, x, mean, log_var) \n",
    "            test_loss += loss_res.item() * x.size(0)\n",
    "\n",
    "    test_loss /= len(data_loader_test.dataset)\n",
    "    logs['test loss'].append(test_loss)\n",
    "\n",
    "    print(\"Test loss : \", test_loss)\n",
    "    \n",
    "    \n",
    "    if args.conditional:\n",
    "        c = torch.randint(0,18,[1000]).long().unsqueeze(1)\n",
    "        imgs = vae.inference(n=c.size(0), c=c)\n",
    "    else:\n",
    "        imgs = vae.inference(n=1000)\n",
    "    print(\"Inception score \", inception_score(imgs, inception_model))\n",
    "    \n",
    "\n",
    "\n",
    "    \"\"\"Print the points of the latent space\"\"\"\n",
    "    df = pd.DataFrame.from_dict(tracker_epoch, orient='index')\n",
    "\n",
    "    if args.representation == None:\n",
    "        g = sns.lmplot(\n",
    "        x='0', y='1', hue='label', data=df.groupby('label').head(100),\n",
    "        fit_reg=False, legend=True)\n",
    "\n",
    "    elif args.representation == \"PCA\":\n",
    "        pca = PCA(n_components=2)\n",
    "        feat_cols = [str(i) for i in range(args.latent_size)]\n",
    "        pca_result = pca.fit_transform(df[feat_cols].values)\n",
    "        df['pca-one'] = pca_result[:,0]\n",
    "        df['pca-two'] = pca_result[:,1]\n",
    "        print('Explained variation per principal component: {}'.format(pca.explained_variance_ratio_))\n",
    "        g = sns.lmplot(\n",
    "        x='pca-one', y='pca-two', hue='label', data=df.groupby('label').head(100),\n",
    "        fit_reg=False, legend=True)\n",
    "\n",
    "    elif args.representation == \"TSNE\":     \n",
    "        time_start = time.time()  \n",
    "        feat_cols = [str(i) for i in range(args.latent_size)] \n",
    "        tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=50)\n",
    "        tsne_results = tsne.fit_transform(df[feat_cols].head(500).values)\n",
    "        df_tsne = df.head(500).copy()\n",
    "        df_tsne['x-tsne'] = tsne_results[:,0]\n",
    "        df_tsne['y-tsne'] = tsne_results[:,1]\n",
    "\n",
    "        print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))\n",
    "\n",
    "        g = sns.lmplot(\n",
    "        x='x-tsne', y='y-tsne', hue='label', data=df_tsne.groupby('label').head(500),\n",
    "        fit_reg=False, legend=True)\n",
    "\n",
    "    g.savefig(os.path.join(\n",
    "        args.fig_root, str(ts), \"E{:d}-Dist.png\".format(epoch)),\n",
    "        dpi=300)\n",
    "\n",
    "\n",
    "\"\"\"Print curves for loss, KL divergence and BCE\"\"\"\n",
    "plt.clf()\n",
    "plt.plot(logs['loss'], label='Loss')\n",
    "plt.savefig(os.path.join(args.fig_root, str(ts),\"loss_summary.png\"),dpi=300)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(logs['test loss'], label='Test Loss')\n",
    "plt.savefig(os.path.join(args.fig_root, str(ts),\"test_loss_summary.png\"),dpi=300)\n",
    "\n",
    "if args.variational or args.conditional:\n",
    "    plt.clf()\n",
    "    plt.plot(logs['KL divergence'], label='KL divergence')\n",
    "    plt.savefig(os.path.join(args.fig_root, str(ts),\"KL_summary.png\"),dpi=300)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.plot(logs['Reconstruction Loss'], label='Reconstruction Loss')\n",
    "    plt.savefig(os.path.join(args.fig_root, str(ts),\"reconstruction_summary.png\"),dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "\n",
    "from load_moonboard import load_moonboard\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=0)\n",
    "parser.add_argument('--batchSize', type=int, default=32, help='input batch size')\n",
    "parser.add_argument('--imageSize', type=int, default=512, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=200, help='size of the latent z vector')\n",
    "parser.add_argument('--ngf', type=int, default=256)\n",
    "parser.add_argument('--ndf', type=int, default=64)\n",
    "parser.add_argument('--niter', type=int, default=70, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='number of GPUs to use')\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--outf', default='.', help='folder to output images and model checkpoints')\n",
    "parser.add_argument('--manualSeed', type=int, help='manual seed')\n",
    "\n",
    "opt = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  6417\n"
     ]
    }
   ],
   "source": [
    "if opt.manualSeed is None:\n",
    "    opt.manualSeed = random.randint(1, 10000)\n",
    "print(\"Random Seed: \", opt.manualSeed)\n",
    "random.seed(opt.manualSeed)\n",
    "torch.manual_seed(opt.manualSeed)\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\"\"\"Load the dataset\"\"\"\n",
    "class MoonBoardDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, train = True):\n",
    "        self.train = train\n",
    "\n",
    "        (self.x_train, self.y_train), (self.x_test, self.y_test) = load_moonboard()\n",
    "        self.x_train = self.x_train.transpose(0,1,3,2 ).astype(float)\n",
    "        self.x_test = self.x_test.transpose(0,1,3,2 ).astype(float)\n",
    "        self.y_train = self.y_train.reshape(-1,1).astype(int)\n",
    "        self.y_test = self.y_test.reshape(-1,1).astype(int)\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.train:\n",
    "            return len(self.x_train)\n",
    "        else:\n",
    "            return len(self.x_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            return self.x_train[idx], self.y_train[idx]\n",
    "        else:\n",
    "            return self.x_test[idx], self.y_test[idx]\n",
    "\n",
    "dataset = MoonBoardDataset(train = True)\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=opt.batchSize,\n",
    "                                         shuffle=True, num_workers=int(opt.workers))\n",
    "\n",
    "nc = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "device = torch.device(\"cuda\")\n",
    "ngpu = int(opt.ngpu)\n",
    "nz = int(opt.nz)\n",
    "ngf = int(opt.ngf)\n",
    "ndf = int(opt.ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (leakyRelu): LeakyReLU(negative_slope=0.2, inplace)\n",
       "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv1_1): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv1_2): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (conv3): Conv2d(128, 1, kernel_size=(5, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.convtrans1 = nn.ConvTranspose2d(nz, ngf * 4, (5,4), 2, 0, bias=False)\n",
    "        self.convtrans2 = nn.ConvTranspose2d(ngf * 4, ngf * 2, (5,4), 2, 2, bias=False)\n",
    "        self.convtrans3 = nn.ConvTranspose2d(    ngf * 2,      nc, (4,3), 2, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(ngf * 4)\n",
    "        self.bn2 = nn.BatchNorm2d(ngf * 2)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "   \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convtrans1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.convtrans2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.convtrans3(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.tanh(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "netG = Generator(ngpu).to(device)\n",
    "netG.apply(weights_init)\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        \n",
    "        self.leakyRelu = nn.LeakyReLU(0.2, inplace=True)\n",
    "        self.bn1 = nn.BatchNorm2d(ndf * 2)\n",
    "        self.bn2 = nn.BatchNorm2d(ndf * 4)\n",
    "        self.bn3 = nn.BatchNorm2d(ndf * 8)\n",
    "        self.conv1_1 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        self.conv1_2 = nn.Conv2d(nc, ndf, 4, 2, 1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, 1, (5,4), 2, 1, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x,y):\n",
    "        lbl = torch.zeros([x.shape[0],3,18,1]).to(\"cuda\")\n",
    "        x = torch.cat([x,lbl],3)\n",
    "        for i,lbl in enumerate(y):\n",
    "            x[i,2,lbl,11] = 1\n",
    "        x = self.conv1_1(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.leakyRelu(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        \n",
    "        return x.view(-1, 1).squeeze(1)\n",
    "\n",
    "\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "netD.apply(weights_init)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=13):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
    "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "    \n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion*planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion*planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "    \n",
    "def inception_score(imgs, inception_model, splits = 1):\n",
    "\n",
    "    N = len(imgs)    \n",
    "    split_scores = []\n",
    "    \n",
    "    preds = nn.Softmax(dim = 1)(inception_model(imgs))\n",
    "    \n",
    "    for k in range(splits):\n",
    "        part = preds[k * (N // splits): (k+1) * (N // splits), :]\n",
    "        py = torch.mean(part, 0)\n",
    "        scores = []\n",
    "        for i in range(part.shape[0]):\n",
    "            pyx = part[i, :]\n",
    "            scores.append(entropy(pyx.cpu().detach().numpy(), py.cpu().detach().numpy()))\n",
    "        split_scores.append(np.exp(np.mean(scores)))\n",
    "\n",
    "    return np.mean(split_scores), np.std(split_scores)\n",
    "    \n",
    "inception_model = torch.load(\"inception_model.trch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "\n",
    "fixed_noise = torch.randn(opt.batchSize, nz, 1, 1, device=device)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(opt.beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception score  (1.8143989, 0.0)\n",
      "[0/70][129/130] Loss_D: 0.3860 Loss_G: 0.5628 D(x): 0.4148 D(G(z)): 0.2087 / 0.2498\n",
      "Inception score  (1.9587616, 0.0)\n",
      "[1/70][129/130] Loss_D: 0.1513 Loss_G: 0.4062 D(x): 0.6713 D(G(z)): 0.2080 / 0.36260\n",
      "Inception score  (1.9516876, 0.0)\n",
      "[2/70][129/130] Loss_D: 0.0960 Loss_G: 0.0113 D(x): 1.0152 D(G(z)): -0.3095 / 0.8939\n",
      "Inception score  (1.8555907, 0.0)\n",
      "[3/70][129/130] Loss_D: 0.0187 Loss_G: 1.5211 D(x): 0.9287 D(G(z)): 0.1169 / -0.2333\n",
      "Inception score  (1.5218003, 0.0)\n",
      "[4/70][129/130] Loss_D: 0.0474 Loss_G: 1.0490 D(x): 1.2177 D(G(z)): -0.0077 / -0.0242\n",
      "Inception score  (2.0150893, 0.0)\n",
      "[5/70][129/130] Loss_D: 0.0632 Loss_G: 0.1349 D(x): 0.8397 D(G(z)): -0.1936 / 0.6327\n",
      "Inception score  (2.1037087, 0.0)\n",
      "[6/70][129/130] Loss_D: 0.1101 Loss_G: 0.0678 D(x): 0.7311 D(G(z)): -0.1943 / 0.73957\n",
      "Inception score  (1.668432, 0.0)\n",
      "[7/70][129/130] Loss_D: 0.1073 Loss_G: 0.8084 D(x): 1.3140 D(G(z)): -0.0931 / 0.1009\n",
      "Inception score  (1.8296229, 0.0)\n",
      "[8/70][129/130] Loss_D: 1.0849 Loss_G: 0.0004 D(x): 0.0007 D(G(z)): -0.2937 / 1.0197\n",
      "Inception score  (2.05487, 0.0)\n",
      "[9/70][129/130] Loss_D: 0.1376 Loss_G: 0.1598 D(x): 1.3095 D(G(z)): -0.2046 / 0.6003\n",
      "Inception score  (2.1730402, 0.0)\n",
      "[10/70][129/130] Loss_D: 0.9227 Loss_G: 0.0419 D(x): 0.0500 D(G(z)): -0.1419 / 0.7952\n",
      "Inception score  (1.9783145, 0.0)\n",
      "[11/70][129/130] Loss_D: 0.1480 Loss_G: 0.0026 D(x): 1.2082 D(G(z)): -0.3235 / 0.9495\n",
      "Inception score  (2.1121426, 0.0)\n",
      "[12/70][129/130] Loss_D: 0.3681 Loss_G: 0.2607 D(x): 0.3996 D(G(z)): -0.0871 / 0.48941\n",
      "Inception score  (2.0896773, 0.0)\n",
      "[13/70][129/130] Loss_D: 1.6477 Loss_G: 0.0000 D(x): -0.2455 D(G(z)): -0.3106 / 0.9935\n",
      "Inception score  (2.0782387, 0.0)\n",
      "[14/70][129/130] Loss_D: 0.1271 Loss_G: 1.8970 D(x): 1.3098 D(G(z)): 0.1763 / -0.3773\n",
      "Inception score  (1.9734002, 0.0)\n",
      "[15/70][129/130] Loss_D: 0.4321 Loss_G: 0.0600 D(x): 1.3969 D(G(z)): -0.5240 / 0.7551\n",
      "Inception score  (1.9824563, 0.0)\n",
      "[16/70][129/130] Loss_D: 0.4407 Loss_G: 0.5327 D(x): 0.3581 D(G(z)): 0.1694 / 0.270174\n",
      "Inception score  (2.0266204, 0.0)\n",
      "[17/70][129/130] Loss_D: 1.3342 Loss_G: 0.1849 D(x): -0.1199 D(G(z)): -0.2830 / 0.5700\n",
      "Inception score  (1.958927, 0.0)\n",
      "[18/70][129/130] Loss_D: 0.1618 Loss_G: 0.0199 D(x): 1.1339 D(G(z)): -0.3793 / 0.85897\n",
      "Inception score  (2.0621657, 0.0)\n",
      "[19/70][129/130] Loss_D: 0.1334 Loss_G: 0.7001 D(x): 1.3083 D(G(z)): -0.1959 / 0.16331\n",
      "Inception score  (2.0230947, 0.0)\n",
      "[20/70][129/130] Loss_D: 0.0030 Loss_G: 1.2405 D(x): 1.0404 D(G(z)): 0.0371 / -0.11380\n",
      "Inception score  (1.9706451, 0.0)\n",
      "[21/70][129/130] Loss_D: 0.0252 Loss_G: 1.2058 D(x): 1.1431 D(G(z)): 0.0687 / -0.09813\n",
      "Inception score  (2.0258687, 0.0)\n",
      "[22/70][129/130] Loss_D: 0.0016 Loss_G: 1.1130 D(x): 1.0322 D(G(z)): 0.0233 / -0.05502\n",
      "Inception score  (2.0160341, 0.0)\n",
      "[23/70][129/130] Loss_D: 0.2536 Loss_G: 0.6816 D(x): 1.4949 D(G(z)): -0.0931 / 0.17443\n",
      "Inception score  (2.016372, 0.0)\n",
      "[24/70][129/130] Loss_D: 0.7536 Loss_G: 0.0237 D(x): 0.1691 D(G(z)): -0.2514 / 0.84609\n",
      "Inception score  (2.022608, 0.0)\n",
      "[25/70][129/130] Loss_D: 0.1055 Loss_G: 1.6914 D(x): 1.3099 D(G(z)): 0.0972 / -0.30057\n",
      "Inception score  (2.0153894, 0.0)\n",
      "[26/70][129/130] Loss_D: 1.0031 Loss_G: 0.8501 D(x): 0.8521 D(G(z)): 0.9906 / 0.078012\n",
      "Inception score  (2.0375547, 0.0)\n",
      "[27/70][129/130] Loss_D: 0.8287 Loss_G: 0.6248 D(x): 0.0927 D(G(z)): 0.0741 / 0.209524\n",
      "Inception score  (2.021135, 0.0)\n",
      "[28/70][129/130] Loss_D: 0.2408 Loss_G: 0.6817 D(x): 1.4804 D(G(z)): -0.1003 / 0.17430\n",
      "Inception score  (2.0387027, 0.0)\n",
      "[29/70][129/130] Loss_D: 2.2448 Loss_G: 0.5210 D(x): 0.1554 D(G(z)): 1.2375 / 0.278284\n",
      "Inception score  (2.0076096, 0.0)\n",
      "[30/70][129/130] Loss_D: 0.7490 Loss_G: 0.0014 D(x): 0.2132 D(G(z)): -0.3605 / 0.96268\n",
      "Inception score  (2.0536366, 0.0)\n",
      "[31/70][129/130] Loss_D: 0.7203 Loss_G: 0.1225 D(x): 0.2863 D(G(z)): -0.4593 / 0.64995\n",
      "Inception score  (2.032431, 0.0)\n",
      "[32/70][129/130] Loss_D: 0.0457 Loss_G: 0.3547 D(x): 1.1491 D(G(z)): -0.1532 / 0.40447\n",
      "Inception score  (1.9902031, 0.0)\n",
      "[33/70][129/130] Loss_D: 0.1395 Loss_G: 0.4670 D(x): 1.3555 D(G(z)): -0.1148 / 0.31667\n",
      "Inception score  (2.0037725, 0.0)\n",
      "[34/70][129/130] Loss_D: 0.0440 Loss_G: 0.7817 D(x): 1.2004 D(G(z)): -0.0620 / 0.11590\n",
      "Inception score  (2.0163147, 0.0)\n",
      "[35/70][129/130] Loss_D: 0.6896 Loss_G: 0.1900 D(x): 0.2218 D(G(z)): -0.2898 / 0.56418\n",
      "Inception score  (2.0340874, 0.0)\n",
      "[36/70][129/130] Loss_D: 0.0538 Loss_G: 1.5296 D(x): 1.1827 D(G(z)): 0.1428 / -0.23683\n",
      "Inception score  (2.0457566, 0.0)\n",
      "[37/70][129/130] Loss_D: 1.2859 Loss_G: 0.6907 D(x): -0.1339 D(G(z)): -0.0080 / 0.1689\n",
      "Inception score  (2.0464368, 0.0)\n",
      "[38/70][129/130] Loss_D: 0.9391 Loss_G: 0.6792 D(x): 0.0319 D(G(z)): -0.0431 / 0.17582\n",
      "Inception score  (2.0372849, 0.0)\n",
      "[39/70][129/130] Loss_D: 0.3250 Loss_G: 0.7370 D(x): 1.3403 D(G(z)): -0.4574 / 0.14151\n",
      "Inception score  (1.9850116, 0.0)\n",
      "[40/70][129/130] Loss_D: 1.1892 Loss_G: 0.8491 D(x): 1.4737 D(G(z)): 0.9822 / 0.078534\n",
      "Inception score  (2.0326755, 0.0)\n",
      "[41/70][129/130] Loss_D: 0.0410 Loss_G: 0.3174 D(x): 1.1370 D(G(z)): -0.1492 / 0.43661\n",
      "Inception score  (2.019365, 0.0)\n",
      "[42/70][129/130] Loss_D: 0.7610 Loss_G: 0.1605 D(x): 0.1278 D(G(z)): 0.0168 / 0.599492\n",
      "Inception score  (2.095249, 0.0)\n",
      "[43/70][129/130] Loss_D: 0.9923 Loss_G: 0.1439 D(x): 0.0822 D(G(z)): -0.3872 / 0.62076\n",
      "Inception score  (2.0815687, 0.0)\n",
      "[44/70][129/130] Loss_D: 0.0812 Loss_G: 1.1563 D(x): 1.2791 D(G(z)): 0.0569 / -0.07537\n",
      "Inception score  (2.025815, 0.0)\n",
      "[45/70][129/130] Loss_D: 0.0414 Loss_G: 0.7056 D(x): 1.2032 D(G(z)): 0.0089 / 0.160056\n",
      "Inception score  (2.0914843, 0.0)\n",
      "[46/70][129/130] Loss_D: 1.2433 Loss_G: 0.0773 D(x): -0.0986 D(G(z)): -0.1909 / 0.7220\n",
      "Inception score  (2.0909078, 0.0)\n",
      "[47/70][129/130] Loss_D: 0.0481 Loss_G: 1.4284 D(x): 1.2046 D(G(z)): 0.0790 / -0.19523\n",
      "Inception score  (2.0329323, 0.0)\n",
      "[48/70][129/130] Loss_D: 0.0731 Loss_G: 0.5284 D(x): 1.2032 D(G(z)): -0.1783 / 0.27318\n",
      "Inception score  (2.0693488, 0.0)\n",
      "[49/70][129/130] Loss_D: 3.4851 Loss_G: 0.1354 D(x): -0.3647 D(G(z)): 1.2738 / 0.63202\n",
      "Inception score  (2.080644, 0.0)\n",
      "[50/70][129/130] Loss_D: 0.0089 Loss_G: 0.7537 D(x): 1.0775 D(G(z)): -0.0535 / 0.13187\n",
      "Inception score  (2.0447826, 0.0)\n",
      "[51/70][129/130] Loss_D: 2.2884 Loss_G: 0.3180 D(x): 0.1036 D(G(z)): 1.2186 / 0.436141\n",
      "Inception score  (2.056441, 0.0)\n",
      "[52/70][129/130] Loss_D: 1.1915 Loss_G: 0.8780 D(x): 1.1554 D(G(z)): 1.0804 / 0.063085\n",
      "Inception score  (2.130526, 0.0)\n",
      "[53/70][129/130] Loss_D: 0.0384 Loss_G: 0.5575 D(x): 0.9755 D(G(z)): -0.1944 / 0.25339\n",
      "Inception score  (2.0567868, 0.0)\n",
      "[54/70][129/130] Loss_D: 0.2217 Loss_G: 0.8567 D(x): 1.4264 D(G(z)): -0.1998 / 0.07448\n",
      "Inception score  (2.1032906, 0.0)\n",
      "[55/70][129/130] Loss_D: 0.6900 Loss_G: 0.6516 D(x): 0.1700 D(G(z)): -0.0337 / 0.19284\n",
      "Inception score  (2.0819612, 0.0)\n",
      "[56/70][129/130] Loss_D: 0.1425 Loss_G: 0.5562 D(x): 1.2793 D(G(z)): -0.2540 / 0.25422\n",
      "Inception score  (2.1003616, 0.0)\n",
      "[57/70][129/130] Loss_D: 0.0737 Loss_G: 0.4985 D(x): 1.1328 D(G(z)): -0.2367 / 0.29405\n",
      "Inception score  (2.1108747, 0.0)\n",
      "[58/70][129/130] Loss_D: 0.7792 Loss_G: 0.5581 D(x): 0.1240 D(G(z)): -0.1091 / 0.25297\n",
      "Inception score  (2.061171, 0.0)\n",
      "[59/70][129/130] Loss_D: 0.6633 Loss_G: 0.7620 D(x): 0.1890 D(G(z)): 0.0752 / 0.127166\n",
      "Inception score  (2.0782747, 0.0)\n",
      "[60/70][129/130] Loss_D: 0.0233 Loss_G: 0.9369 D(x): 1.1367 D(G(z)): -0.0680 / 0.03212\n",
      "Inception score  (2.0816524, 0.0)\n",
      "[61/70][129/130] Loss_D: 0.2122 Loss_G: 0.0650 D(x): 0.9110 D(G(z)): -0.4519 / 0.74510\n",
      "Inception score  (2.1009061, 0.0)\n",
      "[62/70][129/130] Loss_D: 0.2267 Loss_G: 1.2203 D(x): 1.4609 D(G(z)): -0.1196 / -0.1047\n",
      "Inception score  (2.1206508, 0.0)\n",
      "[63/70][129/130] Loss_D: 0.0264 Loss_G: 0.6757 D(x): 1.1570 D(G(z)): -0.0418 / 0.17801\n",
      "Inception score  (2.014098, 0.0)\n",
      "[64/70][129/130] Loss_D: 1.1539 Loss_G: 0.3448 D(x): -0.0559 D(G(z)): -0.1971 / 0.4128\n",
      "Inception score  (2.0635788, 0.0)\n",
      "[65/70][129/130] Loss_D: 1.3756 Loss_G: 0.5302 D(x): -0.1712 D(G(z)): 0.0620 / 0.27191\n",
      "Inception score  (2.1294184, 0.0)\n",
      "[66/70][129/130] Loss_D: 2.2793 Loss_G: 0.4838 D(x): 0.2667 D(G(z)): 1.3196 / 0.304415\n",
      "Inception score  (2.0323288, 0.0)\n",
      "[67/70][129/130] Loss_D: 0.1438 Loss_G: 1.2053 D(x): 1.3560 D(G(z)): 0.1308 / -0.09780\n",
      "Inception score  (2.0924757, 0.0)\n",
      "[68/70][129/130] Loss_D: 0.0531 Loss_G: 0.4468 D(x): 1.0507 D(G(z)): -0.2247 / 0.33163\n",
      "Inception score  (2.0346487, 0.0)\n",
      "[69/70][129/130] Loss_D: 0.0021 Loss_G: 0.8477 D(x): 0.9842 D(G(z)): -0.0434 / 0.07932\n",
      "Inception score  (2.0963767, 0.0)\n"
     ]
    }
   ],
   "source": [
    "ff_noise = torch.randn(1000, nz, 1, 1, device=device)\n",
    "\n",
    "print(\"Inception score \", inception_score(netG(ff_noise), inception_model))\n",
    "best = 0\n",
    "for epoch in range(opt.niter):\n",
    "    for i, (x,y) in enumerate(dataloader, 0):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_cpu = x.type(torch.FloatTensor).to(device)\n",
    "        batch_size = real_cpu.size(0)\n",
    "        label = torch.full((batch_size,), real_label, device=device)\n",
    "\n",
    "        output = netD(real_cpu,y)\n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz-13, 1, 1, device=device)\n",
    "        y_fake = torch.randint(0,12,(batch_size,1))\n",
    "        stck = torch.zeros([batch_size,13,1,1])\n",
    "        for j,v in enumerate(y_fake):\n",
    "            stck[j,v,0,0] = 1\n",
    "        noise = torch.cat([stck.to(\"cuda\"),noise.to(\"cuda\")],1)\n",
    "            \n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        output = netD(fake.detach(),y_fake)\n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        for _ in range(2):\n",
    "            netG.zero_grad()\n",
    "            label.fill_(real_label)  # fake labels are real for generator cost\n",
    "            fake = netG(noise)\n",
    "            output = netD(fake,y_fake)\n",
    "            errG = criterion(output, label)\n",
    "            errG.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            optimizerG.step()\n",
    "\n",
    "        print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f / %.4f'\n",
    "              % (epoch, opt.niter, i, len(dataloader),\n",
    "                 errD.item(), errG.item(), D_x, D_G_z1, D_G_z2), end=\"\\r\")\n",
    "        if i % 100 == 0:\n",
    "            vutils.save_image(real_cpu,\n",
    "                    '%s/real_samples.png' % opt.outf,\n",
    "                    normalize=True)\n",
    "            fake = netG(fixed_noise)\n",
    "            vutils.save_image(fake.detach(),\n",
    "                    '%s/fake_samples_epoch_%03d.png' % (opt.outf, epoch),\n",
    "                    normalize=True)\n",
    "    print(\"\")\n",
    "    isc = inception_score(netG(ff_noise), inception_model)\n",
    "    print(\"Inception score \", isc)\n",
    "    \n",
    "    if isc[0] > best:\n",
    "        best = isc[0]\n",
    "        torch.save(netG.state_dict(), 'bestG.pth')\n",
    "        torch.save(netD.state_dict(), 'bestD.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inception score  (2.4307632, 0.0)\n",
      "4129\n"
     ]
    }
   ],
   "source": [
    "print(\"Inception score \", inception_score(next(iter(dataloader))[0].type(torch.FloatTensor).to(device), inception_model))\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.2574,  0.5887,  0.1926,  0.2037, -0.0903, -0.3972, -0.3110, -0.4885,\n",
      "         -0.6051, -0.6535, -0.6716, -0.8180, -0.8136]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n",
      "[ 3 11 18]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "noise = torch.randn(1, nz-13, 1, 1, device=device)\n",
    "stck = torch.zeros([1,13,1,1])\n",
    "\n",
    "stck[0,0,0,0] = 1\n",
    "\n",
    "z_p = torch.cat([stck.to(\"cuda\"),noise.to(\"cuda\")],1)\n",
    "        \n",
    "z_p = z_p.to(\"cuda\")\n",
    "with torch.autograd.no_grad():\n",
    "    x_p = netG(z_p)\n",
    "#vutils.save_image(x_p.cpu(), \"test.jpg\",normalize=True)\n",
    "print(inception_model(x_p))\n",
    "print(np.flipud(np.swapaxes(np.swapaxes(x_p.view(3,18,11).data.cpu().numpy(),0,1),1,2).shape))\n",
    "plt.imshow(np.flipud(np.swapaxes(np.swapaxes(x_p.view(3,18,11).data.cpu().numpy(),0,1),1,2)))\n",
    "plt.savefig(\"img2017-7.png\",dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.6735,  0.6910,  0.4236,  0.7587,  0.1184, -0.1790, -0.0832, -0.3782,\n",
      "         -0.6487, -0.7707, -0.8587, -1.0107, -0.9982]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f69808538d0>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKoAAAD8CAYAAADnoT9oAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAACl1JREFUeJzt3W2sm3UZx/Hvz80FQRQmMpEtOs0gmURFB8FnEEOGkowXxoxEM5TkJCYgGgyZ+sKXEiU+JBLNCU72AiEGQRYSGHMxGhOdnM3hGBuyIA9nDgYxUaOJY+HyRW9me07PTns/tL3a3ydp+nDutldPfvnfd/vv9a8iArNR95phF2DWCwfVUnBQLQUH1VJwUC0FB9VScFAtBQfVUnBQLYWlg3wySZ4GW9T7+9x+dyNVDNBLEfHmxTYaaFCtFzN9bq9GqhigZ3rZyLt+S6FSUCWtl/SEpEOSNtdVlNlcpYMqaQlwG3AlsBa4RtLaugoza1dlRL0YOBQRT0XEMeBuYEM9ZZl1qhLUc4Hn2q7PFrd1kDQlaUZSv+8SzE5o/F1/REwD0+CPp6y8KiPqYWBV2/WVxW1mtasS1EeANZJWS1oGbAS21VOWWafSu/6IOC7pemA7sATYEhH7a6vMrI0G2dznY9Re9PsvSj8ztTsi1i22kadQR0764DXCU6iWgoNqKTioloKDaik4qJaCg2opOKiWgoNqKTioloKDaik4qJaC5/onTdLvvHhEtRQcVEuhSrv0Kkm/lvS4pP2SbqyzMLN2VY5RjwM3RcQeSacDuyXtiIjHa6rN7ITSI2pEHImIPcXlfwEH6NIubVaHWo5RJb0duBDYVcfjmc1V+eMpSa8HfgF8OSL+2eXvU8BU1eexyVapuU/Sa4EHgO0R8d0etndz37CN3ueoPTX3VXnXL+AnwIFeQmpWRZVj1A8BnwM+LmlvcfpkTXWZdaiyAMXvGJkJNht3nuufNEmHFk+hWgoOqqXgoFoKDqql4KBaCg6qpeCgWgoOqqXgoFoKDqql4KBaCp7rb1KZb98mnYtvmkdUS8FBtRQqB1XSEkl/kvRAHQWZdVPHiHojrVZps8ZUCqqklcCngNvrKcesu6oj6veBm4FXaqjFbEFVulCvAo5GxO5FtpuSNCNppuxzmZXu65f0LVpdqMeBU4A3APdGxGdPcp/J6uv356i96Kmvv5Zfl5Z0KfDViLhqke0c1MU4qF35c1RLoZYRtecn84i6OI+oXXlEtRT8pZQmTd7o2BiPqJaCg2opOKiWgoNqKTioloKDaik4qJaCg2opOKiWgoNqKTioloKDaik4qJZC1S7UMyTdI+mgpAOSPlBXYWbtqn7N7wfAQxHxaUnLgFNrqMlsntJBlfRG4KPAtQARcQw4Vk9ZZp2q7PpXAy8CPy2W9Lld0mk11WXWoUpQlwLvA34UERcC/wY2z93Iff1WhypBnQVmI2JXcf0eWsHtEBHTEbGulwYus4WUDmpEPA88J+n84qbLgcdrqcpsjqrv+m8A7ize8T8FfL56SWbzVQpqROwFvEu3xnlmylJwUC0FB9VScFAtBQfVUnBQLQUH1VJwUC0FB9VScFAtBQfVUnBQLQUH1VIYrzX8+/0VknFYY39CXrNHVEuhal//VyTtl/SYpLsknVJXYWbtqvxo77nAl4B1EXEBsATYWFdhZu2q7vqXAq+TtJTW4hN/q16S2XxVmvsOA7cCzwJHgH9ExMN1FWbWrsqu/0xgA62FKN4KnCZp3k+gu6/f6lBl1/8J4K8R8WJEvAzcC3xw7kbu67c6VAnqs8Alkk6VJFp9/QfqKcusU5Vj1F20VkfZA+wrHmu6prrMOiiizI/Kl3wyqdknm5BZmg75X/PuXg4LPTNlKYzXXH+/o0X+0Wg0a2qAR1RLwUG1FBxUS8FBtRQcVEvBQbUUHFRLwUG1FBxUS8FBtRQcVEthvOb6+zUh8+TjwCOqpeCgWgqLBlXSFklHJT3WdttySTskPVmcn9lsmTbpehlR7wDWz7ltM7AzItYAO+nyq9JmdVo0qBHxW+Dvc27eAGwtLm8Frq65LrMOZd/1r4iII8Xl54EVC20oaQqYKvk8ZkANH09FRJysaS8ipim6Uxtv7rOxVfZd/wuSzgEozo/WV5LZfGWDug3YVFzeBNxfTzlmC4iIk56Au2gtgvYyMAtcB7yJ1rv9J4FfAcsXe5ziscInn+acZnrJzngtQGEZeQEKGx8OqqXgoFoKDqql4KBaCg6qpeCgWgoOqqXgoFoKDqql4KBaCg6qpeCgWgoOqqXgoFoKZfv6vyPpoKQ/S7pP0hnNlmmTrmxf/w7ggoh4N/AX4Gs112XWoVRff0Q8HBHHi6t/AFY2UJvZCXUco34BeHChP0qakjQjaaaG57IJVamvX9I3gOPAnQtt475+q0PpoEq6FrgKuDwG2SFoE6lUUCWtB24GPhYR/6m3JLP5evl46i7g98D5kmYlXQf8EDgd2CFpr6QfN1ynTTj39duwua/fxoeDaik4qJaCg2opOKiWgoNqKTioloKDaik4qJaCg2opOKiWgoNqKTiolkLlX+6zevX79TI1UsXo8YhqKZTq62/7202SQtJZzZRn1lK2rx9Jq4ArgGdrrslsnlJ9/YXv0eqb8rf2rXGljlElbQAOR8SjNddj1lXf7/olnQp8ndZuv5ftp4Cpfp/HrF2ZEfWdwGrgUUlP01rOZ4+kt3TbOCKmI2JdLw1cZgvpe0SNiH3A2a9eL8K6LiJeqrEusw5l+/rNBsp9/SNmAmem3Ndv42Ok5/oncHQZi9fQBI+oloKDaik4qJaCg2opOKiWgoNqKTioloKDaik4qJaCg2opOKiWwkjP9Xve217lEdVSKN3XL+kGSQcl7Zf07eZKNCvZ1y/pMmAD8J6IeBdwa/2lmf1f2b7+LwK3RMR/i22ONlCb2Qllj1HPAz4iaZek30i6qM6izOYq+65/KbAcuAS4CPi5pHd0+zl09/VbHcqOqLPAvdHyR+AVoOtCae7rtzqUDeovgcsAJJ0HLAPc12+NWXTXX/T1XwqcJWkW+CawBdhSfGR1DNjUbbdvVhf39duwua/fxoeDaik4qJaCg2opOKiWgoNqKTioloKDaik4qJaCg2opOKiWgoNqKTiolsKg+/pfAp7pcvtZTNb3WSft9cLCr/ltvdx5oF/zW7AIaWaSOgAm7fVC9dfsXb+l4KBaCqMS1OlhFzBgk/Z6oeJrHoljVLPFjMqIanZSQw2qpPWSnpB0SNLmYdYyKJKelrRP0l5JM8OupwndFtaTtFzSDklPFudn9vOYQwuqpCXAbcCVwFrgGklrh1XPgF0WEe8d44+o7mDOwnrAZmBnRKwBdhbXezbMEfVi4FBEPBURx4C7aa0QaMktsLDeBmBrcXkrcHU/jznMoJ4LPNd2fba4bdwF8LCk3cW6XJNiRUQcKS4/D6zo584jvTT6mPpwRByWdDawQ9LBYgSaGBER/S5GMswR9TCwqu36yuK2sRYRh4vzo8B9tA6BJsELks4BKM77WlN3mEF9BFgjabWkZcBGYNsQ62mcpNMknf7qZeAK4LGT32tsbAM2FZc3Aff3c+eh7foj4rik64HtwBJgS0TsH1Y9A7ICuE8StP73P4uIh4ZbUv0WWFjvFlrr6F5H6xt0n+nrMT0zZRl4ZspScFAtBQfVUnBQLQUH1VJwUC0FB9VScFAthf8BFd5j/5A1KU8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = next(iter(dataloader))[0][0].view(-1, 3, 18, 11).type(torch.FloatTensor).to(device)\n",
    "print(inception_model(img))\n",
    "plt.imshow(np.flipud(np.swapaxes(np.swapaxes(img.view(3,18,11).data.cpu().numpy(),0,1),1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
